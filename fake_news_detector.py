#!/usr/bin/env python3
"""
Fake News Detector - –ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π (REAL/FAKE)
–ü–æ–∏—Å–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (accuracy_score, confusion_matrix, 
                           classification_report, roc_curve, auc)
import re
import os
import glob
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class FakeNewsDetector:
    def __init__(self):
        self.vectorizer = None
        self.model = None
        self.feature_names = None
        
    def find_dataset(self):
        """–ü–æ–∏—Å–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞"""
        print("üîç –ü–æ–∏—Å–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞
        script_dir = os.path.dirname(os.path.abspath(__file__))
        print(f"üìÅ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {script_dir}")
        
        # –ò—â–µ–º CSV —Ñ–∞–π–ª—ã
        csv_files = glob.glob(os.path.join(script_dir, "*.csv"))
        
        if not csv_files:
            # –ü–æ–∫–∞–∂–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            all_files = glob.glob(os.path.join(script_dir, "*"))
            print("üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
            for file in all_files:
                file_name = os.path.basename(file)
                print(f"   - {file_name}")
            raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏!")
        
        print("üìã –ù–∞–π–¥–µ–Ω—ã CSV —Ñ–∞–π–ª—ã:")
        for file in csv_files:
            file_name = os.path.basename(file)
            file_size = os.path.getsize(file) / 1024  # —Ä–∞–∑–º–µ—Ä –≤ KB
            print(f"   - {file_name} ({file_size:.1f} KB)")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª
        preferred_names = ['traindata.csv', 'train.csv', 'data.csv', 'dataset.csv']
        for preferred in preferred_names:
            for file in csv_files:
                if os.path.basename(file).lower() == preferred:
                    print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {preferred}")
                    return file
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π CSV
        selected_file = csv_files[0]
        print(f"‚úÖ –ê–≤—Ç–æ–≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞: {os.path.basename(selected_file)}")
        return selected_file
    
    def load_and_prepare_data(self, file_path=None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if file_path is None:
            file_path = self.find_dataset()
            
        print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {os.path.basename(file_path)}...")
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            encodings = ['utf-8', 'latin-1', 'windows-1251', 'cp1251']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                df = pd.read_csv(file_path, encoding='utf-8', errors='ignore')
                print("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫ –∫–æ–¥–∏—Ä–æ–≤–∫–∏")
                
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} –∑–∞–ø–∏—Å–µ–π, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
        df.columns = [col.lower().strip() for col in df.columns]
        print(f"üìã –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –ü–æ–∫–∞–∂–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print("\nüìä –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
        print(df.head(3))
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –º–µ—Ç–∫–∞–º–∏
        text_columns = []
        label_column = None
        
        # –ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–∫–∏ —Å –º–µ—Ç–∫–∞–º–∏
        label_keywords = ['label', 'class', 'target', 'is_fake', 'type', 'category']
        for col in df.columns:
            if any(keyword in col for keyword in label_keywords):
                label_column = col
                break
        
        if not label_column:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É —Å –¥–≤—É–º—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            for col in df.columns:
                unique_vals = df[col].dropna().unique()
                if len(unique_vals) == 2:
                    label_column = col
                    print(f"üîç –ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –º–µ—Ç–∫–∞–º–∏ (2 –∑–Ω–∞—á–µ–Ω–∏—è): {col}")
                    print(f"   –ó–Ω–∞—á–µ–Ω–∏—è: {unique_vals}")
                    break
        
        # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        text_keywords = ['text', 'content', 'article', 'title', 'news', 'message', 'headline']
        for col in df.columns:
            if col != label_column and df[col].dtype == 'object':
                if any(keyword in col for keyword in text_keywords):
                    text_columns.append(col)
        
        if not text_columns:
            # –í–æ–∑—å–º–µ–º –ø–µ—Ä–≤—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É
            for col in df.columns:
                if col != label_column and df[col].dtype == 'object':
                    text_columns.append(col)
                    break
        
        if not label_column or not text_columns:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:")
            for col in df.columns:
                print(f"   - {col}: {df[col].dtype}, —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {df[col].nunique()}")
                if df[col].dtype == 'object':
                    sample = df[col].iloc[0] if len(df) > 0 else "N/A"
                    print(f"     –ø—Ä–∏–º–µ—Ä: {str(sample)[:50]}...")
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä—É—á–Ω—É—é")
        
        print(f"üè∑Ô∏è –ö–æ–ª–æ–Ω–∫–∞ —Å –º–µ—Ç–∫–∞–º–∏: {label_column}")
        print(f"üìù –ö–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º: {text_columns}")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        df['content'] = ''
        for col in text_columns:
            df['content'] += ' ' + df[col].astype(str)
        
        # –û—á–∏—Å—Ç–∫–∞ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–∫
        df['label'] = df[label_column].astype(str).str.upper().str.strip()
        
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
        label_mapping = {
            'FAKE': 'FAKE', 'FALSE': 'FAKE', '0': 'FAKE', 'F': 'FAKE', 'FAKE NEWS': 'FAKE',
            'REAL': 'REAL', 'TRUE': 'REAL', '1': 'REAL', 'R': 'REAL', 'REAL NEWS': 'REAL'
        }
        
        df['label'] = df['label'].map(label_mapping)
        
        # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–∫–∏, —Å–ø—Ä–æ—Å–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        unknown_labels = df[~df['label'].isin(['FAKE', 'REAL'])]['label'].unique()
        if len(unknown_labels) > 0:
            print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–∫–∏: {unknown_labels}")
            print("üîÑ –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ FAKE/REAL...")
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Å–∏–º–≤–æ–ª—É
            for label in unknown_labels:
                if label and label[0] in ['F', '0']:
                    df.loc[df['label'] == label, 'label'] = 'FAKE'
                elif label and label[0] in ['R', '1', 'T']:
                    df.loc[df['label'] == label, 'label'] = 'REAL'
        
        print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(df['label'].value_counts())
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        initial_count = len(df)
        df = df[df['label'].isin(['FAKE', 'REAL'])]
        final_count = len(df)
        
        if final_count < initial_count:
            print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {initial_count - final_count} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏")
        
        return df[['content', 'label']]
    
    def preprocess_text(self, text):
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if isinstance(text, str):
            text = text.lower()
            text = re.sub(r'[^a-zA-Z\s]', '', text)  # –£–¥–∞–ª—è–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
            text = re.sub(r'\s+', ' ', text).strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            return text
        return ""
    
    def create_visualizations(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–∞–Ω–Ω—ã—Ö"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('üìà –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π', fontsize=16, fontweight='bold')
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
        label_counts = df['label'].value_counts()
        colors = ['#ff6b6b', '#4ecdc4']
        axes[0,0].pie(label_counts.values, labels=label_counts.index, 
                     autopct='%1.1f%%', colors=colors, startangle=90)
        axes[0,0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π')
        
        # 2. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
        df['text_length'] = df['content'].str.len()
        sns.boxplot(data=df, x='label', y='text_length', ax=axes[0,1], palette=colors)
        axes[0,1].set_title('–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º')
        axes[0,1].set_ylabel('–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞')
        axes[0,1].set_xlabel('–ö–ª–∞—Å—Å')
        
        # 3. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º
        df['word_count'] = df['content'].str.split().str.len()
        sns.histplot(data=df, x='word_count', hue='label', 
                    ax=axes[1,0], palette=colors, alpha=0.7)
        axes[1,0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤')
        axes[1,0].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤')
        
        # 4. –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
        axes[1,1].text(0.1, 0.9, "–ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:", fontsize=12, fontweight='bold')
        
        fake_sample = df[df['label']=='FAKE'].iloc[0]['content'] if len(df[df['label']=='FAKE']) > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        real_sample = df[df['label']=='REAL'].iloc[0]['content'] if len(df[df['label']=='REAL']) > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        axes[1,1].text(0.1, 0.7, f"FAKE: {str(fake_sample)[:100]}...", 
                      fontsize=9, color='red')
        axes[1,1].text(0.1, 0.5, f"REAL: {str(real_sample)[:100]}...", 
                      fontsize=9, color='green')
        axes[1,1].axis('off')
        
        plt.tight_layout()
        plt.show()
        
        return df
    
    def train_model(self, df):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        print("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        df['content_clean'] = df['content'].apply(self.preprocess_text)
        X = df['content_clean']
        y = df['label']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –æ–±–∞ –∫–ª–∞—Å—Å–∞
        if len(y.unique()) < 2:
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º—ã –æ–±–∞ –∫–ª–∞—Å—Å–∞ (FAKE –∏ REAL) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"üìö –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìö –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞: {len(X_test)} –∑–∞–ø–∏—Å–µ–π")
        
        # TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        self.vectorizer = TfidfVectorizer(
            stop_words='english',
            max_df=0.7,
            min_df=2,
            ngram_range=(1, 2),
            max_features=5000,
            sublinear_tf=True
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞
        X_train_tfidf = self.vectorizer.fit_transform(X_train)
        X_test_tfidf = self.vectorizer.transform(X_test)
        
        self.feature_names = self.vectorizer.get_feature_names_out()
        print(f"üî° –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ TF-IDF: {X_train_tfidf.shape[1]}")
        
        # –û–±—É—á–µ–Ω–∏–µ PassiveAggressiveClassifier
        self.model = PassiveAggressiveClassifier(
            max_iter=1000,
            random_state=42,
            C=0.5,
            early_stopping=True
        )
        
        self.model.fit(X_train_tfidf, y_train)
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        cv_scores = cross_val_score(self.model, X_train_tfidf, y_train, cv=5)
        print(f"‚úÖ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (5-fold): {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
        
        return X_test_tfidf, y_test, X_train_tfidf, y_train
    
    def evaluate_model(self, X_test, y_test, X_train, y_train):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.decision_function(X_test)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"üéØ –¢–û–ß–ù–û–°–¢–¨ –ú–û–î–ï–õ–ò: {accuracy:.2%}")
        print("\nüìã Classification Report:")
        print(classification_report(y_test, y_pred))
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._plot_results(y_test, y_pred, y_pred_proba, accuracy)
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self._plot_feature_importance()
        
        return accuracy
    
    def _plot_results(self, y_test, y_pred, y_pred_proba, accuracy):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (Accuracy: {accuracy:.2%})', 
                    fontsize=16, fontweight='bold')
        
        # 1. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(y_test, y_pred, labels=['FAKE', 'REAL'])
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'],
                   ax=axes[0,0])
        axes[0,0].set_title('Confusion Matrix')
        axes[0,0].set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
        axes[0,0].set_ylabel('–†–µ–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å')
        
        # 2. ROC –∫—Ä–∏–≤–∞—è (–µ—Å–ª–∏ –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
        try:
            fpr, tpr, _ = roc_curve((y_test == 'REAL').astype(int), y_pred_proba)
            roc_auc = auc(fpr, tpr)
            
            axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, 
                          label=f'ROC curve (AUC = {roc_auc:.2f})')
            axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
            axes[0,1].set_xlim([0.0, 1.0])
            axes[0,1].set_ylim([0.0, 1.05])
            axes[0,1].set_xlabel('False Positive Rate')
            axes[0,1].set_ylabel('True Positive Rate')
            axes[0,1].set_title('ROC Curve')
            axes[0,1].legend(loc="lower right")
            axes[0,1].grid(True)
        except Exception as e:
            axes[0,1].text(0.5, 0.5, "ROC curve not available", 
                          ha='center', va='center', fontsize=12)
            axes[0,1].set_title('ROC Curve')
        
        # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ confidence scores
        if len(np.unique(y_pred_proba)) > 1:
            axes[1,0].hist(y_pred_proba[y_test == 'REAL'], bins=30, alpha=0.7, 
                          label='REAL', color='green')
            axes[1,0].hist(y_pred_proba[y_test == 'FAKE'], bins=30, alpha=0.7, 
                          label='FAKE', color='red')
            axes[1,0].set_xlabel('Confidence Score')
            axes[1,0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            axes[1,0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Confidence Scores')
            axes[1,0].legend()
            axes[1,0].grid(True)
        else:
            axes[1,0].text(0.5, 0.5, "Confidence scores not available", 
                          ha='center', va='center', fontsize=12)
            axes[1,0].set_title('Confidence Scores')
        
        # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        report = classification_report(y_test, y_pred, output_dict=True)
        metrics = ['precision', 'recall', 'f1-score']
        classes = ['FAKE', 'REAL']
        
        x = np.arange(len(classes))
        width = 0.25
        
        for i, metric in enumerate(metrics):
            values = [report[cls][metric] for cls in classes]
            axes[1,1].bar(x + i*width, values, width, label=metric)
        
        axes[1,1].set_xlabel('–ö–ª–∞—Å—Å—ã')
        axes[1,1].set_ylabel('Score')
        axes[1,1].set_title('–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º')
        axes[1,1].set_xticks(x + width)
        axes[1,1].set_xticklabels(classes)
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def _plot_feature_importance(self, top_n=20):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if hasattr(self.model, 'coef_'):
            feature_importance = np.abs(self.model.coef_[0])
            top_indices = np.argsort(feature_importance)[-top_n:]
            top_features = self.feature_names[top_indices]
            top_scores = feature_importance[top_indices]
            
            plt.figure(figsize=(10, 8))
            colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))
            
            bars = plt.barh(range(len(top_features)), top_scores, color=colors)
            plt.yticks(range(len(top_features)), top_features)
            plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞')
            plt.title(f'–¢–æ–ø-{top_n} —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞—Ä—ã
            for bar, score in zip(bars, top_scores):
                plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                        f'{score:.3f}', ha='left', va='center', fontsize=9)
            
            plt.tight_layout()
            plt.show()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    detector = FakeNewsDetector()
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = detector.load_and_prepare_data()
        
        if df is not None and len(df) > 0:
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            df = detector.create_visualizations(df)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            X_test, y_test, X_train, y_train = detector.train_model(df)
            
            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            accuracy = detector.evaluate_model(X_test, y_test, X_train, y_train)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            if accuracy >= 0.90:
                print(f"üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%} > 90%")
            else:
                print(f"‚ö†Ô∏è –¢–æ—á–Ω–æ—Å—Ç—å {accuracy:.2%} –Ω–∏–∂–µ —Ü–µ–ª–µ–≤–æ–π 90%")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()